[CONTROL]
# either regression, or classification
# When setting to classification, examples will be organized by 
# valence/arousal quartiles and the corresponding mood will be be the prediction target.
experiment_type = regression
valence_key = valence
arousal_key = arousal


[PREPROCESSING]
threshold = 0
test_size = 0.20
# case sensitive
meta_cols = query_index,score,submission.score,n_words,n_comments


[FEATURE_SELECTION] 
selector = none
# n_components is the parameter passed to the PCA constructor. 
# This value represents total number of components if 1 <= n < inf
# If 0 < n < 1, then n_components represents the percent of explained variance 
# the PCA will preserve, and find the minimum number of components which fit that criteria. 
n_components = 0.99
# percent_features is only used with selection strategies which aren't PCA.
percent_features = 0.90

[MODEL]
model = lightgbm

# Only use when experiment_type = classification
[SAMPLER]
# Valid samplers include under_sample and SMOTE.
sampling = none


# This section should be specific to the type of model you chose above.
[MODEL_ARGS]

# This section is only used if grid_search = True
# Every parameter should either be in the form of a comma separated list, or 
# param_low, param_high, param_step. 
[GS_PARAMS]
grid_search = true
cv = 5
# See - https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter 
scoring = neg_mean_absolute_error

# This section should be specific to the type of model you chose above.
[PARAM_GRID]

# Tuning grid
params = "[{'model__max_iter': [50,100,150,200,250,500],
            'model__min_samples_leaf': [10,20],
            'model__l2_regularization': [0.0, 0.001, 0.01, 0.1, 1.0],
            'model__loss': ['squared_error'],
            'model__learning_rate': [0.05, 0.1, 0.5, 1],
            'model__max_depth': [None, 10, 25, 50],
            'model__max_leaf_nodes': [15, 25, 31, 50, None]}]"

# Tuned parameters 

; params = "[{'model__max_iter': [100],
;             'model__l2_regularization': [0.01]}]"

